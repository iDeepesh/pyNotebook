{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax\n",
    "# Normalizes all the predicted values by converting them to probabilites that add up to 1.\n",
    "\n",
    "# Softmax formula\n",
    "# x = [x1, x2, x3, ... xn]\n",
    "# s(xi) = exp(xi)/sum(exp(x))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def softmax(x):\n",
    "    # e = np.exp(x)\n",
    "    # e_sum = np.sum(np.exp(x), axis=0)\n",
    "    # r = e/e_sum\n",
    "    # return r\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis=0)\n",
    "\n",
    "# softmax with numpy array using custom softmax function\n",
    "x = np.array([5.4, 3.6, 7.1, 1.9, 4.4])\n",
    "print(f\"Numpy array: {x}\")\n",
    "x_sm = softmax(x)\n",
    "print(f\"Softmaxed numpy array: {x_sm}\")\n",
    "\n",
    "# softmax with tensors using in built softmax function\n",
    "tx = torch.from_numpy(x)\n",
    "print(f\"Tensor: {tx}\")\n",
    "tx_sm = torch.softmax(tx, dim=0)\n",
    "print(f\"Softmaxed Tensor: {tx_sm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy\n",
    "\n",
    "# Formula\n",
    "# cross_entropy D(y_predicted, y_label) = -1/N * sum(y_label_i * log(y_predicted_i))\n",
    "# Lower is the accuracy/correctness of the predicted value, higher is the cross-entropy loss\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# cross entropy with numpy arrays\n",
    "\n",
    "# Note assumptions for custom cross_entropy loss method\n",
    "# Label values must be one hot encoded labels e.g. [0, 0, 1, 0, 0]\n",
    "# Predicted values must be softmaxed probabilities\n",
    "def cross_entropy(y_predicted, y_label):\n",
    "    return -1 * np.sum(y_label * np.log(y_predicted))\n",
    "    # why not divide by the count of the elements in array\n",
    "\n",
    "# assume 3 values of class labels [0, 1, 2]. With one-hot only the correct one is set.\n",
    "y_label = [1, 0, 0]\n",
    "\n",
    "y_pred_good = [0.4, 0.3, 0.3]\n",
    "y_pred_very_good = [0.8, 0.1, 0.1]\n",
    "y_pred_bad = [0.1, 0.6, 0.3]\n",
    "y_pred_very_bad = [0.4, 0.5, 0.1]\n",
    "\n",
    "print(f\"Numpy Cross entropy for good prediction: {cross_entropy(y_pred_good, y_label)}\")\n",
    "print(f\"Numpy Cross entropy for very good prediction: {cross_entropy(y_pred_very_good, y_label)}\")\n",
    "print(f\"Numpy Cross entropy for bad prediction: {cross_entropy(y_pred_bad, y_label)}\")\n",
    "print(f\"Numpy Cross entropy for very bad prediction: {cross_entropy(y_pred_very_bad, y_label)}\")\n",
    "\n",
    "\n",
    "# cross entropy with nn built in functions\n",
    "# No softmax in last layer of neural networks because\n",
    "# nn.CrossEntropyLoss applies (log softmax + negative log likelihood loss)\n",
    "# y_labes has class labels, not One-Hot encoding\n",
    "# y_predicted has raw scores, no softmax\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# single sample\n",
    "# assume 3 values of class labels [0, 1, 2]\n",
    "y_label = torch.tensor([1])\n",
    "# n_samples * n_classes = 1*3\n",
    "y_prediction_good = torch.tensor([[1.0, 2.0, 0.1]])\n",
    "y_prediction_bad = torch.tensor([[7.5, 4.2, 0.9]])\n",
    "\n",
    "print(f\"Single sample: Pytorch Cross entropy loss for good prediction: {loss(y_prediction_good, y_label):3f}\")\n",
    "print(f\"Single sample: Pytorch Cross entropy loss for bad prediction: {loss(y_prediction_bad, y_label):3f}\")\n",
    "\n",
    "# multiple samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
